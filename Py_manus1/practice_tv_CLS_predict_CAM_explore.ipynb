{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3751a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use hsvw3 env\n",
    "#Add kernel\n",
    "#run on Volta notes\n",
    "#Load 3 modules\n",
    "\n",
    "import os, time, datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import sys\n",
    "import torch.nn.functional as F # noqa\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from Py_common.tv_utils import fix_all_seeds_torch\n",
    "from Py_common.tv_Dataset_strips import ValDataset_strips\n",
    "from TV.CBAM import  ResNet50_CBAM, predict, find_item,tensor_to_rgb_image, CAM_Manual \n",
    "from TV.CBAM import plot_unique_gradient_histgram, plot_gradient_heatmap, select_info, order_informations, plot_individual_maps, get_topk_rankedby_overall_and_specific\n",
    "from TV.CBAM import LabelProcessor, get_prediction_df, compute_performance, get_sorted_feature_idx_abs, show_cam_on_image\n",
    "from TV.CBAM import AllImageInfo, get_sorted_score_idxes, normalize_to_minus_one_to_one, symlog_transform, mean_std_norm\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import re\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2883e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_function(selected_ids,test_ds,image_obj,scores_df,top_oa_idxes,top_oa_scores,save_loc):\n",
    "    \n",
    "    for selected_sp in selected_ids:\n",
    "        #get image\n",
    "        img, label, sp_id  = find_item(test_ds, selected_sp)\n",
    "        img = img.to(device)    \n",
    "\n",
    "        #Get RGB img\n",
    "        rgb_img = tensor_to_rgb_image(img) #Get RGB img for plot\n",
    "\n",
    "        #Get patient indx\n",
    "        pt_idx = all_ids_test.index(selected_sp)\n",
    "\n",
    "        #Get all info\n",
    "        cur_grad, cur_score_map, cur_cam_norm_ori, cur_cam_resized, cur_featuremaps, cur_pred_class = image_obj[pt_idx] #NOTE: cur_cam_norm =  normed version of cur_score_map.sum(axis = 0)\n",
    "\n",
    "        #Get CAM before normlization\n",
    "        cur_cam = cur_score_map.sum(axis = 0)\n",
    "\n",
    "        #Get current image specifc scores for each feature\n",
    "        cur_score_sum = np.array(scores_df[selected_sp]) #this is equal to cur_score_map.sum(axis = (1,2)) \n",
    "\n",
    "        #Print overall\n",
    "#         print('TOP feature overall:', top_oa_idxes)\n",
    "#         print('TOP score overall:',top_oa_scores)\n",
    "\n",
    "        #Get top K specific feature\n",
    "        cur_idxes_sorted = get_sorted_score_idxes(cur_score_sum, use_abs = True)\n",
    "        top_k = 7\n",
    "        top_sp_idxes =  cur_idxes_sorted[0:top_k]\n",
    "        top_sp_scores = cur_score_sum[top_sp_idxes].round(2)\n",
    "#         print('TOP feature specific:', top_sp_idxes)\n",
    "#         print('TOP score specific:',top_sp_scores)\n",
    "\n",
    "        #Get Top specific, but not in overall\n",
    "        top_sp_idxes2 = [f for f in cur_idxes_sorted if f not in top_oa_idxes][0:top_k]\n",
    "        top_sp_scores2 = cur_score_sum[top_sp_idxes2].round(2)\n",
    "#         print('TOP feature specific:2', top_sp_idxes2)\n",
    "#         print('TOP score specific2:',top_sp_scores2)\n",
    "\n",
    "\n",
    "        rgb_image = rgb_img\n",
    "        fig_size = (30,16)\n",
    "        cmap = 'RdYlBu_r'\n",
    "        \n",
    "\n",
    "        #All\n",
    "        cur_cam2 = cur_cam/cur_cam.max()\n",
    "\n",
    "        const = cur_score_map.max()\n",
    "        cur_score_map2 = [x/const for x in cur_score_map]\n",
    "\n",
    "        #All\n",
    "        combs = np.append([cur_cam2],cur_score_map2, axis = 0)\n",
    "\n",
    "        #Norm for acroos all maps\n",
    "        combs = combs - combs.min() \n",
    "        combs = combs/combs.max()\n",
    "\n",
    "        #select\n",
    "        scores =  list(cur_score_sum[top_oa_idxes + top_sp_idxes2])\n",
    "        selected_scores_overall = list(scores_overall[top_oa_idxes + top_sp_idxes2])\n",
    "\n",
    "        #Modify index\n",
    "        top_oa_idxes_modified = [x +1 for x in top_oa_idxes]\n",
    "        top_sp_idxes_modified = [x +1 for x in top_sp_idxes2]\n",
    "        feature_idxes =  [0] + top_oa_idxes_modified + top_sp_idxes_modified\n",
    "        plot_array = combs[feature_idxes]\n",
    "\n",
    "\n",
    "        vis_list = []\n",
    "        f_idx_list = []\n",
    "        score_list = []\n",
    "        score_overall_list = []\n",
    "        for i in range(len(feature_idxes)):\n",
    "\n",
    "\n",
    "            #resize\n",
    "            if i>0:\n",
    "                cur_score = scores[i-1]\n",
    "                cur_score_overall = selected_scores_overall[i-1]\n",
    "            else:\n",
    "                cur_score = None\n",
    "                cur_score_overall = None\n",
    "            heatmap = plot_array[i,]\n",
    "            heatmap = cv2.resize(heatmap, (rgb_image.shape[1], rgb_image.shape[0]))\n",
    "\n",
    "            #Overlay heatmap to img\n",
    "            vis = show_cam_on_image(rgb_image, heatmap, cmap = cmap, use_rgb=False, use_custom_cmap = True, image_weight = 0.5, cam_method = vis_method)\n",
    "\n",
    "            vis_list.append(vis)\n",
    "            f_idx_list.append(feature_idxes[i])\n",
    "            score_list.append(cur_score)\n",
    "            score_overall_list.append(cur_score_overall)\n",
    "\n",
    "        # Plot the heatmaps\n",
    "        vis_list = [rgb_image] + vis_list\n",
    "        f_idx_list = ['-1'] + f_idx_list\n",
    "        score_list = ['-1'] + score_list\n",
    "        score_overall_list = ['-1'] + score_overall_list\n",
    "\n",
    "        fig, axes = plt.subplots(1, len(vis_list), figsize=fig_size)\n",
    "\n",
    "        for i, ax in enumerate(axes):\n",
    "            im = ax.imshow(vis_list[i], cmap=cmap)\n",
    "            ax.set_xticks([])  # Remove x ticks\n",
    "            ax.set_yticks([])  # Remove y ticks\n",
    "\n",
    "            if i == 0:\n",
    "                ax.set_title('Image \\n', fontsize=15)\n",
    "            elif i == 1:\n",
    "                ax.set_title('CAM \\n', fontsize=15)\n",
    "            else:\n",
    "                ax.set_title(f\"F{int(f_idx_list[i])-1} \\nOA:{float(score_overall_list[i]):.2f} \\nSP:{float(score_list[i]):.2f} \", fontsize=15)\n",
    "\n",
    "        \n",
    "        # Add a vertical dashed line \n",
    "        fig.subplots_adjust(wspace=0.1)  \n",
    "\n",
    "        # Get the x position of the 11th and 12th subplot\n",
    "        x_left = axes[int(len(vis_list)/2)].get_position().x1  \n",
    "        x_right = axes[int(len(vis_list)/2 + 1)].get_position().x0  \n",
    "        x_middle = (x_left + x_right) / 2  # Middle of the white space\n",
    "\n",
    "        # Correct way to add a vertical dashed line\n",
    "        line = mpl.lines.Line2D([x_middle, x_middle], [0.18, 0.9], transform=fig.transFigure,\n",
    "                                color='black', linestyle='dashed', linewidth=2)\n",
    "        fig.lines.append(line)  # Add the line to the figure\n",
    "\n",
    "            \n",
    "            \n",
    "        #Normalize colormap since the first image use differnt scale \n",
    "        norm = mpl.colors.Normalize(vmin=0, vmax=255)  # \n",
    "        sm = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])  # Empty array, as we only need the colormap\n",
    "\n",
    "        # Add a shared color bar at the bottom\n",
    "        cbar = plt.colorbar(sm, ax=axes, orientation='horizontal', fraction=0.046, pad=0.04, extend='neither')\n",
    "        tick_positions = np.linspace(0, 255, 6)\n",
    "        tick_labels = np.linspace(-1, 1, 6)\n",
    "        cbar.set_ticks(tick_positions)\n",
    "        cbar.set_ticklabels([f\"{t:.1f}\" for t in tick_labels])  # Format labels from -1 to 1\n",
    "\n",
    "        save_path4 = os.path.join(save_loc, 'Top9OAandTOP9SP')\n",
    "        if not os.path.exists(save_path4):\n",
    "            os.makedirs(save_path4)        \n",
    "        \n",
    "        if cur_pred_class != label:\n",
    "            save_path_mis = os.path.join(save_path4, 'Misclassified')\n",
    "            \n",
    "            if not os.path.exists(save_path_mis):\n",
    "                os.makedirs(save_path_mis)\n",
    "            final_path = save_path_mis\n",
    "        else:\n",
    "            final_path = save_path4 \n",
    "            \n",
    "        plt_title =  selected_sp + '\\n Predicted Class ' + str(cur_pred_class) +  ' True Class: ' + str(label)\n",
    "        map_title = 'Score Map\\n' + plt_title\n",
    "        plt.suptitle(map_title, fontsize=17)     \n",
    "        \n",
    "        plt.savefig(os.path.join(final_path, selected_sp + \"_Score_Map.png\"), dpi=300, bbox_inches='tight', pad_inches=0, facecolor='white')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedcb216",
   "metadata": {},
   "source": [
    "## target-section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cecc03d-6a26-41a0-a3ae-b585df53e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "input_data_name = \"SEG_sS1_strips_v4\" #SEG_sS1_strips_v6, SEG_sS1_strips_v4, DET_dS_strips\n",
    "label_file = '../../Image/sS_labels.csv'\n",
    "diagnostic_type = 'Final'\n",
    "num_classes = 2\n",
    "mask_dir = 'None'\n",
    "data_aug_ctrl = 1\n",
    "batch_size = 24\n",
    "test_img_dir = '../../Image/test_' + input_data_name\n",
    "model_name = 'CLS_HSV2_Final_2classes_SEG_sS1_strips_v4_pretrained_seed0'\n",
    "model_path = os.path.join('../../Model/', model_name +'.pth')\n",
    "out_location = \"../../Output/output03092025/\"\n",
    "# Extract the integer after \"HSV\" from model name\n",
    "match = re.search(r'HSV(\\d+)', model_name)\n",
    "HSV = int(match.group(1)) if match else None\n",
    "\n",
    "#Selelcted for heatmap plot\n",
    "vis_method = 'CAM'\n",
    "\n",
    "# need to set visibility before defining device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "### Check whether gpu is available\n",
    "if torch.cuda.is_available():\n",
    "    gpu = True\n",
    "    device = torch.device('cuda')  # this will use the visible gpu\n",
    "else:\n",
    "    gpu = False\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# set seeds\n",
    "fix_all_seeds_torch(gpu_id)\n",
    "\n",
    "### Set Directory\n",
    "outdir = os.path.join(out_location, model_name, input_data_name, 'HSV' + str(HSV))\n",
    "save_path = os.path.join(outdir, \"heatmap\")\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "########     Load test data     ########\n",
    "########################################\n",
    "test_ds = ValDataset_strips(img_dir= test_img_dir,\n",
    "                         label_file=label_file,\n",
    "                         HSV=HSV,\n",
    "                         diagnostic_type=diagnostic_type,\n",
    "                         num_classes=num_classes,\n",
    "                         mask_dir=None if mask_dir == 'None' else mask_dir,\n",
    "                         nchan = None # assuming we will supply strip images and mask_dir is None\n",
    "                )\n",
    "print(f\"Number of samples: {len(test_ds)}\")\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "n_batches_test = len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9e235-c69e-49a7-b8d9-251187860945",
   "metadata": {},
   "source": [
    "## Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff7e12-69d0-474e-8864-c31214098e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########    Construct Model     ########\n",
    "########################################\n",
    "nchan=test_ds.nchan\n",
    "print(f\"nchan: {nchan}\")\n",
    "\n",
    "# Load model\n",
    "if 'CBAM' in model_name:\n",
    "    model = ResNet50_CBAM(nchan = nchan, num_classes = num_classes, pretrained_model = \"Resnet50_withPretrainedWeight\", use_cbam_class = True, reduction_ratio = 1, kernel_cbam = 3, freeze = False)\n",
    "    cbam_flag = True\n",
    "else:\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "    model.conv1 = nn.Conv2d(nchan, 64, kernel_size=7, stride=2, padding=3, bias=False) # Train1\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    cbam_flag = False\n",
    "    \n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "print('Model Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771b4e7-12fa-4802-b681-51cd40ef0b8e",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae56882-3383-46d6-bd0d-8f31d8e94051",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_test, accuracy_test, correct_test, auc_test , all_ids_test, all_scores_test, all_labels_test = predict(test_loader,model, device, criterion)\n",
    "\n",
    "#Load label file\n",
    "label_df = pd.read_csv(label_file)\n",
    "label_processor = LabelProcessor(label_df, diagnostic_type)\n",
    "label_df = label_processor.process_labels()\n",
    "\n",
    "#Pred\n",
    "pred_df = get_prediction_df(all_ids_test, all_scores_test, all_labels_test, label_df, pred_thres = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536bad81",
   "metadata": {},
   "source": [
    "## Get All CAM, HEATMAP, GRADIENT, ACTIVATION, FEATURE MAP for all test IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e1eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# Get All CAM, HEATMAP, GRADIENT, ACTIVATION, FEATURE MAP for all test IDs\n",
    "############################################################################################################\n",
    "cam_list = []\n",
    "heatmap_list = []\n",
    "gradient_list = []\n",
    "scores_list = []\n",
    "feature_map_list = []\n",
    "pred_class_list =[]\n",
    "\n",
    "for strip_id in all_ids_test:\n",
    "    img, label, sp_id  = find_item(test_ds, strip_id)\n",
    "    img = img.to(device)\n",
    "    img_tensor = img.unsqueeze(0).to(device)  \n",
    "\n",
    "\n",
    "    cur_pred_df = pred_df.loc[pred_df['strip_id'] == strip_id]\n",
    "    cur_pred_class = cur_pred_df['PRED_CLASS'].item()\n",
    "\n",
    "    #Initializae\n",
    "    cam_ranka = CAM_Manual(model=model, cam_method = vis_method, opposite_class = False, CBAM_FLAG = False)\n",
    "    \n",
    "    #Get cam: avg/sum overall all activation map; heatmap: resized cam, gradients gradients (alphas), and raw_scores (grad*feature map), feature_maps are the feature maps from CNN\n",
    "    cam, heatmap, gradients, raw_scores, feature_maps = cam_ranka(img_tensor)\n",
    "\n",
    "    cam_list.append(cam.unsqueeze(0).cpu().numpy())\n",
    "    heatmap_list.append(np.expand_dims(heatmap, axis=0))\n",
    "    gradient_list.append(gradients.cpu().numpy())\n",
    "    scores_list.append(raw_scores.cpu().numpy())\n",
    "    feature_map_list.append(feature_maps.cpu().numpy()) \n",
    "    pred_class_list.append(cur_pred_class)\n",
    "\n",
    "cam_all = np.vstack(cam_list)\n",
    "heatmap_all = np.vstack(heatmap_list)\n",
    "gradient_all = np.vstack(gradient_list)\n",
    "score_all = np.vstack(scores_list)\n",
    "feature_map_all = np.vstack(feature_map_list)\n",
    "pred_class_all = np.vstack(pred_class_list)\n",
    "\n",
    "print(\"Gradient:\",gradient_all.shape)\n",
    "print(\"Scores:\",score_all.shape)\n",
    "print(\"CAM:\",cam_all.shape)\n",
    "print(\"Heatmap (resized CAM):\",heatmap_all.shape)\n",
    "print(\"Feature maps:\",feature_map_all.shape)\n",
    "print(\"Predicted Class:\",pred_class_all.shape)\n",
    "#Create image object for all test image\n",
    "image_obj = AllImageInfo(gradient_all, score_all, cam_all, heatmap_all, feature_map_all, pred_class_all)\n",
    "\n",
    "# sum over axis 2 and 3 of score_all to get the final score\n",
    "out = score_all.sum(axis=(2,3))\n",
    "# transpose to make columns correspond to strip ids\n",
    "out = np.transpose(out)\n",
    "# save out to a csv file and use all_ids_test as column names\n",
    "np.savetxt(os.path.join(save_path, 'score_by_feature_testimage.csv'), out, delimiter=',', header=','.join(all_ids_test), comments=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ab006-5a13-4591-b193-16caf472e348",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Vsiluzation of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7d6d3-bcee-42bd-8b31-f21ea67215d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A. Top 10 Gradients for all strip id\n",
    "file_path = os.path.join(save_path, \"gradient_all_heatmap.png\")\n",
    "plot_gradient_heatmap(gradient_all, 10, pred_class_all, file_path, HSV, vis_method, sort_by_grad = True, sort_by_class = True)\n",
    "\n",
    "#B. Histograms of Unique Gradient for strip id\n",
    "grad_unique, idx_unique = np.unique(gradient_all, axis=0, return_index=True)\n",
    "grad_class = pred_class_all[idx_unique].flatten().tolist()\n",
    "\n",
    "file_path = os.path.join(save_path, \"gradient_unique_hist.png\")\n",
    "plot_unique_gradient_histgram(grad_unique, grad_class, HSV, vis_method, file_path)\n",
    "\n",
    "#C.TOP 10 (By Abs Gradeints) features for CLASS1 and CLASS0\n",
    "top_f = 10\n",
    "top_f_dict = {}\n",
    "for i in range(2):\n",
    "    top_f_idxes = np.argsort(abs(grad_unique), axis=1)[i][::-1].tolist()[0:top_f]\n",
    "    top_f_dict[grad_class[i]] = top_f_idxes\n",
    "print(top_f_dict)\n",
    "\n",
    "file_path = os.path.join(save_path, \"TOP_Gradient_FeaturesIndex_byClass.txt\")\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(str(top_f_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cb3478-0ca8-4670-a383-6611ff8fccf1",
   "metadata": {},
   "source": [
    "## Get average abs score = sum(grad*feature) over all test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1971e-fccc-4b9a-bbdf-7eeb313c39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.read_csv(os.path.join(save_path, 'score_by_feature_testimage.csv'))\n",
    "scores_overall = np.array(scores_df.abs().mean(axis = 1)) #average over all samples\n",
    "\n",
    "#Compare\n",
    "path1 = '/fh/fast/fong_y/HSVW/Feature/CLS_HSV' + str(HSV) + '_Final_2classes_SEG_sS1_strips_v4_pretrained_seed0.pth/score_by_feature_testimage.csv'\n",
    "check1 = pd.read_csv(path1)\n",
    "\n",
    "print(check1.equals(scores_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7eae1-4638-4ea2-8786-e880facd750d",
   "metadata": {},
   "source": [
    "## Get top k overall score and index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c473a-454f-4a34-a652-44cd5800167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_idxes_sorted = get_sorted_score_idxes(scores_overall, use_abs = True)\n",
    "top_k = 7\n",
    "top_oa_idxes = feature_idxes_sorted[0:top_k]\n",
    "top_oa_scores = scores_overall[top_oa_idxes].round(3)\n",
    "print('TOP feature overall:', top_oa_idxes)\n",
    "print('TOP score overall:',top_oa_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c09f9c",
   "metadata": {},
   "source": [
    "### Plot CAM and indiviudal score maps\n",
    "#### Normalization Note:\n",
    " - because CAM is not in the same scale as the rest of score map\n",
    " -  1st:  norm CAM , CAM/CAM.max() \n",
    " -  2nd: norm other heatmaps, heatmap_i/all_heatmaps.max()\n",
    " -  3rd: norm to 0 to 1 altogether, now all color scale are fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e16b6",
   "metadata": {},
   "source": [
    "## 1. HSV1+, HSV2- (Correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24094fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get IDs\n",
    "grp = 'HSV1POS_HSV2NEG'\n",
    "cond = (pred_df['GROUP'] == grp) & (pred_df['Label'] == pred_df['PRED_CLASS'])\n",
    "selected_ids = list(pred_df.loc[cond, 'strip_id'])\n",
    "print('Plot for ' + grp + \": \" + str(len(selected_ids)))\n",
    "\n",
    "#Create output folder\n",
    "save_path2 = os.path.join(save_path, grp)\n",
    "if not os.path.exists(save_path2):\n",
    "    os.makedirs(save_path2)\n",
    "\n",
    "plot_function(selected_ids,test_ds,image_obj,scores_df,top_oa_idxes,top_oa_scores,save_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b1c96",
   "metadata": {},
   "source": [
    "## 2. HSV1+, HSV2+ (Correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4545b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get IDs\n",
    "grp = 'HSV1POS_HSV2POS'\n",
    "selected_ids = list(pred_df.loc[pred_df['GROUP'] == grp, 'strip_id'])\n",
    "print('Plot for ' + grp + \": \" + str(len(selected_ids)))\n",
    "\n",
    "\n",
    "#Create output folder\n",
    "save_path2 = os.path.join(save_path, grp)\n",
    "if not os.path.exists(save_path2):\n",
    "    os.makedirs(save_path2)\n",
    "\n",
    "plot_function(selected_ids,test_ds,image_obj,scores_df,top_oa_idxes,top_oa_scores,save_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91067dbf",
   "metadata": {},
   "source": [
    "## 3. HSV1-, HSV2+ (Correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb6c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get IDs\n",
    "grp = 'HSV1NEG_HSV2POS'\n",
    "selected_ids = list(pred_df.loc[pred_df['GROUP'] == grp, 'strip_id'])\n",
    "print('Plot for ' + grp + \": \" + str(len(selected_ids)))\n",
    "\n",
    "\n",
    "#Create output folder\n",
    "save_path2 = os.path.join(save_path, grp)\n",
    "if not os.path.exists(save_path2):\n",
    "    os.makedirs(save_path2)\n",
    "\n",
    "plot_function(selected_ids,test_ds,image_obj,scores_df,top_oa_idxes,top_oa_scores,save_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad5395",
   "metadata": {},
   "source": [
    "## 4. HSV1-, HSV2- (Correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get IDs\n",
    "grp = 'HSV1NEG_HSV2NEG'\n",
    "selected_ids = list(pred_df.loc[pred_df['GROUP'] == grp, 'strip_id'])\n",
    "print('Plot for ' + grp + \": \" + str(len(selected_ids)))\n",
    "\n",
    "\n",
    "#Create output folder\n",
    "save_path2 = os.path.join(save_path, grp)\n",
    "if not os.path.exists(save_path2):\n",
    "    os.makedirs(save_path2)\n",
    "\n",
    "plot_function(selected_ids,test_ds,image_obj,scores_df,top_oa_idxes,top_oa_scores,save_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3ca879",
   "metadata": {},
   "source": [
    "## 1. HSV1+, HSV2- (Misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = 'HSV1POS_HSV2NEG'\n",
    "cond = (pred_df['GROUP'] == grp) & (pred_df['Label'] != pred_df['PRED_CLASS'])\n",
    "selected_ids = list(pred_df.loc[cond, 'strip_id'])\n",
    "print('Plot for ' + grp + \": \" + str(len(selected_ids)))\n",
    "\n",
    "#Create output folder\n",
    "save_path2 = os.path.join(save_path, grp)\n",
    "if not os.path.exists(save_path2):\n",
    "    os.makedirs(save_path2)\n",
    "\n",
    "plot_function(selected_ids,test_ds,image_obj,scores_df,top_oa_idxes,top_oa_scores,save_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b978aa89",
   "metadata": {},
   "source": [
    "## 2. HSV1+, HSV2+  (Misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e247170",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = 'HSV1POS_HSV2POS'\n",
    "cond = (pred_df['GROUP'] == grp) & (pred_df['Label'] != pred_df['PRED_CLASS'])\n",
    "selected_ids = list(pred_df.loc[cond, 'strip_id'])\n",
    "print('Plot for ' + grp + \": \" + str(len(selected_ids)))\n",
    "\n",
    "#Create output folder\n",
    "save_path2 = os.path.join(save_path, grp)\n",
    "if not os.path.exists(save_path2):\n",
    "    os.makedirs(save_path2)\n",
    "\n",
    "plot_function(selected_ids,test_ds,image_obj,scores_df,top_oa_idxes,top_oa_scores,save_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc9502",
   "metadata": {},
   "source": [
    "## 3. HSV1-, HSV2+  (Misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b180783",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = 'HSV1NEG_HSV2POS'\n",
    "cond = (pred_df['GROUP'] == grp) & (pred_df['Label'] != pred_df['PRED_CLASS'])\n",
    "selected_ids = list(pred_df.loc[cond, 'strip_id'])\n",
    "print('Plot for ' + grp + \": \" + str(len(selected_ids)))\n",
    "\n",
    "#Create output folder\n",
    "save_path2 = os.path.join(save_path, grp)\n",
    "if not os.path.exists(save_path2):\n",
    "    os.makedirs(save_path2)\n",
    "\n",
    "plot_function(selected_ids,test_ds,image_obj,scores_df,top_oa_idxes,top_oa_scores,save_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345c5861",
   "metadata": {},
   "source": [
    "## 4. HSV1-, HSV2-  (Misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1188327",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = 'HSV1NEG_HSV2NEG'\n",
    "cond = (pred_df['GROUP'] == grp) & (pred_df['Label'] != pred_df['PRED_CLASS'])\n",
    "selected_ids = list(pred_df.loc[cond, 'strip_id'])\n",
    "print('Plot for ' + grp + \": \" + str(len(selected_ids)))\n",
    "\n",
    "#Create output folder\n",
    "save_path2 = os.path.join(save_path, grp)\n",
    "if not os.path.exists(save_path2):\n",
    "    os.makedirs(save_path2)\n",
    "\n",
    "plot_function(selected_ids,test_ds,image_obj,scores_df,top_oa_idxes,top_oa_scores,save_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb350e",
   "metadata": {},
   "source": [
    "### Plot for other cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ids = ['2016.09.22_CZ_03_217','2016.09.01_CZ_01_251','2016.09.22_CZ_02_239','2016.09.22_CZ_03_215', '2016.09.22_CZ_03_213', '2016.09.22_CZ_03_211', '2016.09.01_CZ_03_249', '2016.10.31_CZ_01_231' ]\n",
    "save_path6 = os.path.join(outdir, \"heatmap\", \"other_exp\")\n",
    "if not os.path.exists(save_path6):\n",
    "    os.makedirs(save_path6)\n",
    "plot_function(selected_ids,test_ds,image_obj,scores_df,top_oa_idxes,top_oa_scores,save_path6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
