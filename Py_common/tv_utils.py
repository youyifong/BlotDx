# -*- coding: utf-8 -*-
"""
Created on Dec 8, 2024

@author: Youyi
"""

import cv2, os, torch, random
import numpy as np
from tsp import normalize99


def random_rotate_and_resize_sheet(X, Y=None, scale_range=1., xy = (448,448),
                             do_flip=True, rescale=None, random_per_image=True, do_rotate=True, permute_B_R=False, sharpening=False):
    """ augmentation by random rotation and resizing
    Args:
        X: LIST of ND-arrays, float
            list of image arrays of size [nchan x Ly x Lx] or [Ly x Lx]
        Y: LIST of ND-arrays, float (optional, default None)
            list of image labels of size [nlabels x Ly x Lx] or [Ly x Lx]. The 1st channel
            of Y is always nearest-neighbor interpolated (assumed to be masks or 0-1 representation).
        scale_range: float (optional, default 1.0)
            Range of resizing of images for augmentation. Images are resized by
            (1-scale_range/2) + scale_range * np.random.rand()
        xy: tuple, int (optional, default (224,224))
            size of transformed images to return
        do_flip: bool (optional, default True)
            flip images horizontally or vertically, controlled by local variable flip_horizontally and flip_vertically
        rescale: array, float (optional, default None)
            how much to resize images by before performing augmentations
        random_per_image: bool (optional, default True)
            different random rotate and resize per image
        do_rotate:
        permute_B_R:

    Returns:
        imgi: ND-array, float
            transformed image in array [nchan x xy[0] x xy[1]]
        labeled: ND-array, float
            transformed label in array [nchan x xy[0] x xy[1]]

    Notes
    -----
    1. X should be normalized before inputting this function.
    2. Some gt masks transformed by this function can have the same pixel values in x-axis or y-axis. E.g. boxes=[0,1,0,10] or [5,5,10,5].
    3. Some patch generated by this function can have no gt masks (all pixel values are 0)

    """


    nimg = len(X)
    if X[0].ndim>2:
        nchan = X[0].shape[0]
        # assert that the first dimension is the channel
        assert X[0].shape[0] < X[0].shape[-1]
    else:
        nchan = 1
    imgi  = np.zeros((nimg, nchan, xy[0], xy[1]), np.float32)

    if permute_B_R and nchan==3:
        # permutation B and R channel
        random_number = random.randint(0, 1)
        if random_number == 1:
            X[0] = X[0][[2, 1, 0], ...]

    scale_range = max(0., min(2., float(scale_range)))

    lbl = []
    nt = None
    if Y is not None:
        if Y[0].ndim>2:
            nt = Y[0].shape[0]
        else:
            nt = 1
        lbl = np.zeros((nimg, nt, xy[0], xy[1]), np.float32)
    
    scale = np.ones(nimg, np.float32)

    M=None
    flip_horizontally = False
    flip_vertically = False
    for n in range(nimg):
        Ly, Lx = X[n].shape[-2:]
        
        if random_per_image or n==0:
            # generate random augmentation parameters
            flip_horizontally = np.random.rand()>.5
            flip_vertically = np.random.rand()>.5
            do_sharpening = np.random.rand()>.5

            if do_rotate:
                theta = np.random.rand() * np.pi * 2
            else:
                theta = 0            
            scale[n] = (1-scale_range/2) + scale_range * np.random.rand()
            if rescale is not None:
                scale[n] *= 1. / rescale[n]
            
            # random translation is achieved by dxy and warpAffine taking a patch
            dxy = np.maximum(0, np.array([Lx*scale[n]-xy[1],Ly*scale[n]-xy[0]]))
            dxy = (np.random.rand(2,) - .5) * dxy
            
            # create affine transform
            cc = np.array([Lx/2, Ly/2])
            cc1 = cc - np.array([Lx-xy[1], Ly-xy[0]])/2 + dxy
            pts1 = np.float32([cc,cc + np.array([1,0]), cc + np.array([0,1])])
            pts2 = np.float32([cc1,
                    cc1 + scale[n]*np.array([np.cos(theta), np.sin(theta)]),
                    cc1 + scale[n]*np.array([np.cos(np.pi/2+theta), np.sin(np.pi/2+theta)])])
            M = cv2.getAffineTransform(pts1,pts2)
        
        img = X[n].copy()
        if Y is not None:
            labels = Y[n].copy()
            if labels.ndim<3:
                labels = labels[np.newaxis,:,:] # increase dim

            if flip_horizontally and do_flip:
                labels = labels[..., ::-1]
            if flip_vertically and do_flip:
                labels = labels[..., ::-1, :]
        else:
            labels = None

        if flip_horizontally and do_flip:
            img = img[..., ::-1] 
        if flip_vertically and do_flip:
            img = img[..., ::-1, :] 
        if sharpening and do_sharpening:
            # Gaussian blur sharpening
            # print(img.shape)
            img = np.ascontiguousarray(img.transpose(1, 2, 0))
            blur = cv2.GaussianBlur(img, (0, 0), sigmaX=3)
            amount = 1.5    # strength of sharpening
            img = cv2.addWeighted(img, 1 + amount, blur, -amount, 0)
            img = img.transpose(2, 0, 1)


        # transform image, one channel at a time
        for k in range(nchan):
            I = cv2.warpAffine(img[k], M, (xy[1],xy[0]), flags=cv2.INTER_LINEAR)
            imgi[n,k] = I
        
        # transform masks, one class of objects at a time
        if Y is not None:
            for k in range(nt):
                if k==0:
                    lbl[n,k] = cv2.warpAffine(labels[k], M, (xy[1],xy[0]), flags=cv2.INTER_NEAREST)
                else:
                    lbl[n,k] = cv2.warpAffine(labels[k], M, (xy[1],xy[0]), flags=cv2.INTER_LINEAR) # no need for mask rcnn
        
    return imgi[0], lbl[0]


def random_rotate_and_resize_strip(X, random_per_image=True,
                                   scale_range=0.2, rescale=None,
                                   do_flip=True,
                                   do_rotate=True,
                                   permute_B_R=True, sharpening=False):
    """ augmentation by random rotation and resizing
        X and Y are lists or arrays of length nimg, with dims channels x Ly x Lx (channels optional)
        Parameters
        ----------
        X: LIST of ND-arrays, float. list of image arrays of size [nchan x Ly x Lx] or [Ly x Lx]
        scale_range: float. If 0.2, means 90% to 110% of the original size. Set to 0 to disable
        rescale: array, float (optional, default None)  much to resize images by before performing augmentations
        do_flip: bool (optional, default True) flip images horizontally
        do_rotate: bool (optional, default True) rotation images, 2 degrees max
        permute_B_R: bool (optional, default False) permutation B and R channel for both strips
        random_per_image: bool (optional, default True) different random rotate and resize per image
        permute_B_R: permute B and R channels

        Returns
        -------
        imgi: ND-array, float
            transformed image in array [nchan x xy[0] x xy[1]]
        labeled: ND-array, float
            transformed label in array [nchan x xy[0] x xy[1]]

        Notes
        -----
        1. X should be normalized before inputting this function.
    """

    xy = X[0].shape[1:]

    if permute_B_R:
        # permutation B and R channel for both strips
        # Generate a random 0 or 1
        random_number = random.randint(0, 1)
        if random_number == 1:
            if X[0].shape[0] == 6:
                X[0] = X[0][[2, 1, 0, 5, 4, 3], ...]
            elif X[0].shape[0] == 3:
                X[0] = X[0][[2, 1, 0], ...]
            else:
                raise ValueError("The number of channels in the strip is not 3 or 6")

    scale_range = max(0., min(2., float(scale_range))) # between 0 and 2
    nimg = len(X)
    if X[0].ndim > 2:
        nchan = X[0].shape[0]
    else:
        nchan = 1
    imgi = np.zeros((nimg, nchan, xy[0], xy[1]), np.float32)

    scale = np.ones(nimg, np.float32)

    M=None
    for n in range(nimg):
        Ly, Lx = X[n].shape[-2:]

        if random_per_image or n == 0:
            # generate random augmentation parameters
            if do_rotate:
                theta = np.random.rand() * np.pi * 2 / 180 # 360/180=2 degrees max
            else:
                theta = 0
            scale[n] = (1 - scale_range / 2) + scale_range * np.random.rand()
            if rescale is not None:
                scale[n] *= 1. / rescale[n]

            do_sharpening = np.random.rand()>.5

            # random translation is achieved by dxy and warpAffine taking a patch
            dxy = np.maximum(0, np.array([Lx * scale[n] - xy[1], Ly * scale[n] - xy[0]]))
            dxy = (np.random.rand(2, ) - .5) * dxy

            # create affine transform
            cc = np.array([Lx / 2, Ly / 2])
            cc1 = cc - np.array([Lx - xy[1], Ly - xy[0]]) / 2 + dxy
            pts1 = np.float32([cc, cc + np.array([1, 0]), cc + np.array([0, 1])])
            pts2 = np.float32([cc1,
                               cc1 + scale[n] * np.array([np.cos(theta), np.sin(theta)]),
                               cc1 + scale[n] * np.array([np.cos(np.pi / 2 + theta), np.sin(np.pi / 2 + theta)])])
            M = cv2.getAffineTransform(pts1, pts2)

        img = X[n].copy()

        if do_flip:
            img = img[..., ::-1]

        if sharpening and do_sharpening:
            # Gaussian blur sharpening
            # print(img.shape)
            img = np.ascontiguousarray(img.transpose(1, 2, 0))
            blur = cv2.GaussianBlur(img, (0, 0), sigmaX=3)
            amount = 1.5    # strength of sharpening
            img = cv2.addWeighted(img, 1 + amount, blur, -amount, 0)
            img = img.transpose(2, 0, 1)

        # transform image, one channel at a time
        for k in range(nchan):
            I = cv2.warpAffine(img[k], M, (xy[1], xy[0]), flags=cv2.INTER_LINEAR)
            imgi[n, k] = I


    return imgi[0]



def normalize_img(img):
    """ normalize each channel of the image so that 0.0=0 percentile and 1.0=100 percentile of image intensities
    
    Parameters
    ------------
    img: ND-array (at least 3 dimensions), channel can be either the first or the last dimnension
    
    Returns
    ---------------
    img: ND-array, float32
        normalized image of same size
    """

    if img.ndim<3:
        error_message = 'Image needs to have at least 3 dimensions'
        #transforms_logger.critical(error_message)
        raise ValueError(error_message)
    
    img = img.astype(np.float32)

    def normalize99(Y, lower=1, upper=99):
        """ normalize image so 0.0 is 1st percentile and 1.0 is 99th percentile """
        X = Y.copy()
        x01 = np.percentile(X, lower)
        x99 = np.percentile(X, upper)
        X = (X - x01) / (x99 - x01)
        return X

    # if channel is the first dimension
    if img.shape[0] < img.shape[-1]:

        for k in range(img.shape[0]):
            # ptp can still give nan's with weird images
            i100 = np.percentile(img[k],100)
            i0 = np.percentile(img[k],0)
            if i100 - i0 > +1e-3: #np.ptp(img[k]) > 1e-3:
                img[k] = normalize99(img[k])
            else:
                img[k] = 0

    else:
        for k in range(img.shape[-1]):
            i100 = np.percentile(img[...,k],100)
            i0 = np.percentile(img[...,k],0)
            if i100 - i0 > +1e-3:
                img[...,k] = normalize99(img[...,k])
            else:
                img[...,k] = 0

    return img



# the first three functions are copied from cellpose

### Random seed
def fix_all_seeds_torch(seed):

    np.random.seed(seed)
    random.seed(seed)

    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

    torch.use_deterministic_algorithms(True)

    # PYTHONHASHSEED controls set operations
    # the line below does not actually work, it needs to be set in bash, e.g. export PYTHONHASHSEED=1
    os.environ['PYTHONHASHSEED'] = str(seed)

    # export CUBLAS_WORKSPACE_CONFIG=:4096:8 did not help either



#################################################
# copied and modified from CellSeg CVsegmenter.py

# img needs to be of shape ... x height x width
def crop_with_overlap(img, overlap, nrows, ncols):
    crop_height, crop_width = img.shape[-2]//nrows, img.shape[-1]//ncols
    crops = []
    for row in range(nrows):
        for col in range(ncols):
            x1, y1, x2, y2 = col*crop_width, row*crop_height, (col+1)*crop_width, (row+1)*crop_height
            x1, x2, y1, y2 = get_overlap_coordinates(overlap, nrows, ncols, row, col, x1, x2, y1, y2)
            crops.append(img[..., y1:y2, x1:x2])
    # print("Dividing image into", len(crops), "crops with", nrows, "rows and", ncols, "columns")
    return crops


def get_overlap_coordinates(overlap, rows, cols, i, j, x1, x2, y1, y2):
    half = overlap // 2
    if i != 0:
        y1 -= half
    if i != rows - 1:
        y2 += half
    if j != 0:
        x1 -= half
    if j != cols - 1:
        x2 += half
    return (x1, x2, y1, y2)


def remove_overlapping_pixels(mask, other_masks):
    for other_mask in other_masks:
        if np.sum(np.logical_and(mask, other_mask)) > 0:
            mask[np.logical_and(mask, other_mask)] = 0
    return mask

def remove_overlaps(masks, cellpix, medians):
    """ replace overlapping mask pixels with mask id of closest mask
        masks = Nmasks x Ly x Lx
    """
    overlaps = np.array(np.nonzero(cellpix>1.5)).T # 1.5
    dists = ((overlaps[:,:,np.newaxis] - medians.T)**2).sum(axis=1)
    tocell = np.argmin(dists, axis=1)
    masks[:, overlaps[:,0], overlaps[:,1]] = 0
    masks[tocell, overlaps[:,0], overlaps[:,1]] = 1
    
    # labels should be 1 to mask.shape[0]
    masks = masks.astype(int) * np.arange(1,masks.shape[0]+1,1,int)[:,np.newaxis,np.newaxis]
    masks = masks.sum(axis=0)
    return masks
